{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectif ",
    "\n",
    "Construire un mdèle de reconnaissence d'émotion depuis la parole.\n",
    "\n",
    "\n",
    "Un autre dépôt contient un modèle de détection d'émotions à partir des images et des vidéos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de données utilisé est extraite de RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song) dataset.\n",
    "Téléchargable gratuitement du lien suivant : https://drive.google.com/file/d/1wWsrN2Ep7x6lWqOXfr4rpKGYrJhWc8z7/view\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caractéristiques et variables (Features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables sur lequel nos modèles vont se baser pour détecter l'émotion seront les suivants :\n",
    "\n",
    "   __chroma__ : Concerne les 12 différentes classes de ton\n",
    "\n",
    "   **mfcc** : Mel Frequency Cepstral Coefficients\n",
    "        \n",
    "   **mel** : Mel Spectrogram Frequency\n",
    "\n",
    "On utilisera la librairie **librosa** pour extraire ces variables.\n",
    "\n",
    "Notre fonction prend en entrée des booleans indiquant, pour chaque variable, si on la prend comme feature ou pas.\n",
    "\n",
    "Pour plus de détails sur la signification : http://themarvinproject.free.fr/final/node4.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Extract features (mfcc, chroma, mel) from a sound file\n",
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous n'allons garder que quatres classes parmi les 8 déjà présents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emotions in the RAVDESS dataset\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "#Emotions to observe\n",
    "observed_emotions=['calm', 'happy', 'fearful', 'disgust']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivante prend en paramètre le pourcentage des données en test et renvoie sous forme d'arrays\n",
    "les données d'entrainement et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'entrainement d'un modèle de réseaux de neurones nous seront amené à encoder nos labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer()"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DataFlair - Load the data and extract features for each sound file\n",
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(\"speech-emotion-recognition-ravdess-data/Actor_*/*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)\n",
    "\n",
    "#Split the dataset\n",
    "x_train,x_test,y_train,y_test=load_data(test_size=0.25)\n",
    "\n",
    "#Encoding labels\n",
    "le = preprocessing.LabelBinarizer()\n",
    "le.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples :  576 ; Test samples :  192\n",
      "number of features :  180\n"
     ]
    }
   ],
   "source": [
    "#DataFlair - Get the shape of the training and testing datasets\n",
    "print('Training samples : ',x_train.shape[0],'; Test samples : ', x_test.shape[0])\n",
    "print('number of features : ',x_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va essayer de tester deux modèles dans ce notebook.\n",
    "\n",
    "Le premier est celui de MLPClassifier de Keras qui utilise un réseaux de neurones interne et le deuxième est un simple modèle de réseaux de neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFlair - Initialize the Multi Layer Perceptron Classifier\n",
    "MLP=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)\n",
    "\n",
    "#Full neural network model\n",
    "Fnn = Sequential()\n",
    "Fnn.add(Dense(300,input_dim=180,activation='relu'))\n",
    "Fnn.add(Dense(128,activation='relu'))\n",
    "Fnn.add(Dense(4,activation='softmax'))\n",
    "\n",
    "Fnn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
       "              learning_rate='adaptive', max_iter=500)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fnn.fit(x_train,le.transform(y_train),epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester les modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps on va tester les deux modèles sur\n",
    "un seul ensemble de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.83      0.94      0.88        47\n",
      "     disgust       0.87      0.61      0.71        66\n",
      "     fearful       0.76      0.71      0.73        52\n",
      "       happy       0.43      0.70      0.54        27\n",
      "\n",
      "    accuracy                           0.73       192\n",
      "   macro avg       0.72      0.74      0.72       192\n",
      "weighted avg       0.77      0.73      0.73       192\n",
      "\n",
      "FNN classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        calm       0.91      0.96      0.93        50\n",
      "     disgust       0.87      0.68      0.76        59\n",
      "     fearful       0.86      0.71      0.78        59\n",
      "       happy       0.45      0.83      0.59        24\n",
      "\n",
      "    accuracy                           0.78       192\n",
      "   macro avg       0.77      0.80      0.76       192\n",
      "weighted avg       0.82      0.78      0.79       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict for the test set using MLP model\n",
    "y_pred=MLP.predict(x_test)\n",
    "print(\"MLP classification report\")\n",
    "print(classification_report(y_pred,y_test))\n",
    "\n",
    "#Test the FNN model\n",
    "y_pred=le.inverse_transform(Fnn.predict(x_test))\n",
    "print(\"FNN classification report\")\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "On peut voir que le modèle de réseaux de neurones donne des résultats meuilleurs que MLPClassifier .\n",
    "\n",
    "Pour confirmer cette conclusion on applique une validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  [67.53246753 70.77922078 68.18181818 81.04575163 72.54901961]\n",
      "72.02% (+/- 4.86%)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(MLP,np.vstack((x_train,x_test)),y_train+y_test,cv=5)\n",
    "print(\"accuracy : \",scores*100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(scores*100), np.std(scores*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 77.27%\n",
      "accuracy: 77.27%\n",
      "accuracy: 74.03%\n",
      "accuracy: 78.43%\n",
      "accuracy: 80.39%\n",
      "77.48% (+/- 2.07%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "X = np.vstack((x_train,x_test))\n",
    "Y = np.array(y_train+y_test)\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, Y):\n",
    "    Fnn = Sequential()\n",
    "    Fnn.add(Dense(300,input_dim=180,activation='relu'))\n",
    "    Fnn.add(Dense(128,activation='relu'))\n",
    "    Fnn.add(Dense(4,activation='softmax'))\n",
    "    Fnn.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    Fnn.fit(X[train], le.transform(Y[train]),batch_size=10, verbose=0,epochs=100)\n",
    "    # evaluate the model\n",
    "    scores = Fnn.evaluate(X[test], le.transform(Y[test]), verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (Fnn.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
